{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Learning\\Anaconda3\\envs\\py37\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from sklearn import preprocessing\n",
    "tqdm.pandas()\n",
    "\n",
    "# Configuring notebook env\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Data munging & preparation\n",
    "df_job = pd.read_csv(r'D:\\vanhack\\data\\JobsToPredict.csv')\n",
    "df_job = df_job.rename(columns={'POSITION':'JobsPosition','Skills':'JobSkills','Responsibilities':'JobResponsibilities'})\n",
    "df_job.columns = df_job.columns.str.lower()\n",
    "\n",
    "df_available = pd.read_csv(r'D:\\vanhack\\data\\AvailableCandidates.csv')\n",
    "df_available = df_available.rename(columns={'Skills':'UserSkills'})\n",
    "df_available.columns = df_available.columns.str.lower()\n",
    "df_available = df_available[['userid','userskills','usersposition']]\n",
    "df_available = df_available.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a superset with all jobs available and all candidates available\n",
    "full_df=[]\n",
    "for i in range(len(df_available)):\n",
    "    for j in range(len(df_job)):\n",
    "        #a = round(len(list(set(Candidates_df['Skills'][i]) & set(HiredCandidates_df['Skills'][j])))/len(HiredCandidates_df['Skills'][j]),2)\n",
    "        user_id = df_available['userid'][i]\n",
    "        user_position = df_available['usersposition'][i]\n",
    "        user_skills  = df_available['userskills'][i]\n",
    "        job_id = df_job['jobid'][j]\n",
    "        job_position = df_job['jobsposition'][j]\n",
    "        job_skills = df_job['jobskills'][j]\n",
    "        full_df.append({'userid': user_id, 'userskills': user_skills, 'usersposition': user_position, 'jobid': job_id, 'jobsposition': job_position, 'jobskills': job_skills })\n",
    "full_df = pd.DataFrame(full_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████▎                                                                                                                                                             | 6132/100000 [00:42<11:48, 132.46it/s]"
     ]
    }
   ],
   "source": [
    "# Feature engineering and calculating match score based on weights from lgb model\n",
    "def create_features(row):\n",
    "\n",
    "    user_skills = str(row['userskills']).split(',')\n",
    "    job_skills = str(row['jobskills']).split(',')\n",
    "\n",
    "    user_skills = [x.strip(' ') for x in user_skills]\n",
    "    job_skills = [x.strip(' ') for x in job_skills]\n",
    "\n",
    "    common_skills = []\n",
    "    other_skills = []\n",
    "\n",
    "    for skill in user_skills:\n",
    "        skill = skill.strip()\n",
    "        if skill in job_skills:\n",
    "            common_skills.append(skill)\n",
    "        else:\n",
    "            other_skills.append(skill)\n",
    "          \n",
    "            \n",
    "    row['userskills_no'] = len(user_skills)\n",
    "    row['jobskills_no'] = len(job_skills)\n",
    "    row['common_skills_no'] = len(common_skills)\n",
    "    row['common_skills_text'] = common_skills\n",
    "    \n",
    "    row['common_skills_ratio'] = (len(common_skills)/len(job_skills)) # 1 is ideal\n",
    "    row['other_skills_ratio'] = (len(other_skills)/len(user_skills)) # 0 is ideal\n",
    "    row['job_candiate_skill_ratio'] = (len(job_skills)/len(user_skills)) # 1 is ideal\n",
    "\n",
    "    #row['position_match'] = process.extractOne(str(row['user_UsersPosition']), str(row['job_POSITION']) ,scorer=fuzz.token_sort_ratio)[1]\n",
    "    row['position_match'] = fuzz.token_sort_ratio(str(row['usersposition']), str(row['jobsposition']))\n",
    "        \n",
    "    #     score                  feature\n",
    "    #        4            position_match\n",
    "    #        3       common_skills_ratio\n",
    "    #        3             userskills_no\n",
    "    #        2  job_candiate_skill_ratio\n",
    "    #        1        other_skills_ratio\n",
    "          \n",
    "    return row\n",
    "\n",
    "[ 'common_skills_ratio','position_match','userskills_no','job_candiate_skill_ratio','other_skills_ratio']\n",
    "\n",
    "\n",
    "df = full_df.progress_apply(create_features,axis=1)\n",
    "df.to_csv('df.csv')\n",
    "features = [ 'userskills_no','common_skills_ratio','other_skills_ratio','job_candiate_skill_ratio','position_match']\n",
    "df[features] = preprocessing.MinMaxScaler().fit_transform(df[features])\n",
    "\n",
    "#df['match_score'] =  4*df['common_skills_ratio'] + 5*df['position_match'] +df['userskills_no']# - 2*df['job_candiate_skill_ratio'] - df['other_skills_ratio']\n",
    "df['match_score'] =  3*df['common_skills_ratio'] + 5*df['position_match'] +5*df['userskills_no']# - 2*df['job_candiate_skill_ratio'] - df['other_skills_ratio']\n",
    "\n",
    "df['match_score'] = df['match_score'] * 10\n",
    "\n",
    "df = df.sort_values(by='match_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering to only top 10 candidates by match score for each job\n",
    "result = pd.DataFrame(df.groupby('jobid').head(10)).reset_index()\n",
    "result.drop('index', axis = 1, inplace=True)\n",
    "result.sort_values('jobsposition', axis = 0, inplace=True)\n",
    "\n",
    "# Filtering to only essential features in result\n",
    "essential_features = ['jobid', 'jobsposition', 'jobskills', 'userid', 'usersposition', 'userskills', 'match_score']\n",
    "result = result[essential_features]\n",
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Have not used features Years of experience, English level as they are not included in training data and the only way to use them in prediction would be to hard code importance based on intuition\n",
    "* Used LGB Model because of\n",
    "* Create viz on correlation between years of Exp and English level\n",
    "\n",
    "Further room for improvements:\n",
    "* Analyze responsblities data\n",
    "* Get more training data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
